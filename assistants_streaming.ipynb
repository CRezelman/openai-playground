{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPEN_AI_API_KEY = os.getenv('OPEN_AI_API_KEY')\n",
    "OPEN_AI_ASST_ID = os.getenv('OPEN_AI_ASST_ID')\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPEN_AI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.retrieve(\n",
    "    assistant_id=OPEN_AI_ASST_ID\n",
    ")\n",
    "assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Thread\n",
    "Here we can create a thread, think of it as a new \"chat\". We can add as many messages we want to the thread. We can see the entire thread history of all user and AI repsonse messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()\n",
    "thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a Message to the Thread\n",
    "Here we can add our user defined messages to the thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=(\n",
    "        f\"Create a 2D Maze of with grid dimension of 10.\"\n",
    "        f\"Once the maze is generated, call the solve maze function to solve the maze.\"\n",
    "    )\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Run and Stream Updates\n",
    "Here we tell the Assistant to run the messages we added to thread. We also check if the run submitted any tool outputs (ie. Function Calls). If a function call is submitted we check which function was called and run our own function to return the result to Open AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "from openai.types.beta.threads.run import Run\n",
    "from maze import solve_maze_bfs, create_maze, highlight_path\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    " \n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_event(self, event):\n",
    "        if event.event == 'thread.run.requires_action':\n",
    "            run_id = event.data.id\n",
    "            self.handle_requires_action(event.data, run_id)\n",
    " \n",
    "    def handle_requires_action(self, data: Run, run_id):\n",
    "        tool_outputs = []\n",
    "            \n",
    "        for tool in data.required_action.submit_tool_outputs.tool_calls:\n",
    "            if tool.function.name == \"generate_maze\":\n",
    "                generator_inputs: dict = json.loads(tool.function.arguments)\n",
    "                generator_dim = generator_inputs.get('dimension')\n",
    "                generated_maze = create_maze(dim=generator_dim)\n",
    "\n",
    "                tool_outputs.append({\n",
    "                    \"tool_call_id\": tool.id,\n",
    "                    \"output\": json.dumps(generated_maze)\n",
    "                })\n",
    "            elif tool.function.name == \"solve_maze\":\n",
    "                solve_inputs: dict = json.loads(tool.function.arguments)\n",
    "                solve_maze = solve_inputs.get('grid')\n",
    "                solved_path = solve_maze_bfs(maze=solve_maze)\n",
    "                highlighted_maze = highlight_path(solve_maze, solved_path)\n",
    "\n",
    "                solved_output: dict = {\n",
    "                    \"path_status\": \"Path Found\" if solved_path else \"No Path Found\",\n",
    "                    \"solution_path\": solved_path,\n",
    "                    \"highlighted_maze\": highlighted_maze\n",
    "                }\n",
    "                tool_outputs.append({\n",
    "                    \"tool_call_id\": tool.id,\n",
    "                    \"output\": json.dumps(solved_output)\n",
    "                })\n",
    "        \n",
    "        self.submit_tool_outputs(tool_outputs, run_id)\n",
    " \n",
    "    def submit_tool_outputs(self, tool_outputs, run_id):\n",
    "        with client.beta.threads.runs.submit_tool_outputs_stream(\n",
    "            thread_id=self.current_run.thread_id,\n",
    "            run_id=self.current_run.id,\n",
    "            tool_outputs=tool_outputs,\n",
    "            event_handler=EventHandler(),\n",
    "        ) as stream:\n",
    "            markdown_text = \"\"\n",
    "            for text in stream.text_deltas:\n",
    "                markdown_text += text\n",
    "                print(text, end=\"\", flush=True)\n",
    "\n",
    "            display(Markdown(markdown_text))\n",
    "    \n",
    " \n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    event_handler=EventHandler()\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
